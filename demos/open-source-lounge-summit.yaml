---
namespaces:
  - name: model-serving
    labels:
      opendatahub.io/dashboard: "true"
    annotations:
      openshift.io/description: Project for housing model servers
      openshift.io/display-name: Model Serving
applications:
  - name: aws-nvidia-gpu-machinesets
    values:
      instanceType: g6e.2xlarge
      desiredReplicas: 5
  - name: nvidia-gpu-enablement
  - name: vllm-chart
    fileprefix: granite-33-8b
    rewrite:
      metadata:
        name: granite-33-8b
      spec:
        destination:
          namespace: model-serving
    values:
      fullnameOverride: granite-33-8b
      configuration:
        hfModelDownload:
          enabled: false
        modelStorage:
          type: image
          image:
            type: modelCar
            reference: quay.io/jharmison/models:ibm-granite--granite-3_3-8b-instruct-modelcar
        extraArgs:
          - --served-model-name=ibm-granite/granite-3.3-8b-instruct
  - name: vllm-chart
    fileprefix: llama-32-3b
    rewrite:
      metadata:
        name: llama-32-3b
      spec:
        destination:
          namespace: model-serving
    values:
      fullnameOverride: llama-32-3b
      configuration:
        hfModelDownload:
          enabled: false
        modelStorage:
          type: image
          image:
            type: modelCar
            reference: quay.io/jharmison/models:redhatai--llama-3_2-3b-instruct-fp8-modelcar
        extraArgs:
          - --served-model-name=RedHatAI/Llama-3.2-3B-Instruct-FP8
  - name: vllm-chart
    fileprefix: qwen-3-8b
    rewrite:
      metadata:
        name: qwen-3-8b
      spec:
        destination:
          namespace: model-serving
    values:
      fullnameOverride: qwen-3-8b
      configuration:
        hfModelDownload:
          enabled: false
        modelStorage:
          type: image
          image:
            type: modelCar
            reference: quay.io/jharmison/models:qwen--qwen3-8b-fp8-modelcar
        extraArgs:
          - --served-model-name=Qwen/Qwen3-8B-FP8
  - name: vllm-chart
    fileprefix: mistral-31-24b
    rewrite:
      metadata:
        name: mistral-31-24b
      spec:
        destination:
          namespace: model-serving
    values:
      fullnameOverride: mistral-31-24b
      configuration:
        hfModelDownload:
          enabled: false
        modelStorage:
          type: image
          image:
            type: modelCar
            reference: quay.io/jharmison/models:redhatai--mistral-small-3_1-24b-instruct-2503-fp8-dynamic-modelcar
        extraArgs:
          - --served-model-name=RedHatAI/Mistral-Small-3.1-24B-Instruct-2503-FP8-dynamic
          - --max-model-len=65536
  - name: vllm-chart
    fileprefix: bge-m3
    rewrite:
      metadata:
        name: bge-m3
      spec:
        destination:
          namespace: model-serving
    values:
      fullnameOverride: bge-m3
      configuration:
        hfModelDownload:
          enabled: false
        modelStorage:
          type: image
          image:
            type: modelCar
            reference: podman pull quay.io/jharmison/models:baai--bge-m3-modelcar
        extraArgs:
          - --served-model-name=BAAI/bge-m3
          - --enforce-eager
