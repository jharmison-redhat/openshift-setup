---
namespaces:
  - name: model-serving
    labels:
      opendatahub.io/dashboard: "true"
    annotations:
      openshift.io/description: Project for housing model servers
      openshift.io/display-name: Model Serving
applications:
  - name: aws-nvidia-gpu-machinesets
    values:
      instanceType: g6e.2xlarge
      autoscaling:
        enabled: true
        minReplicas: 1
        maxReplicas: 3
  - name: nvidia-gpu-enablement
  - name: openshift-serverless
  - name: openshift-servicemesh
  - name: authorino
  - name: openshift-ai
    values:
      dashboardReplicas: 1
      dataScienceClusterComponents:
        codeflare:
          managementState: Removed
        datasciencepipelines:
          managementState: Removed
        ray:
          managementState: Removed
        trainingoperator:
          managementState: Removed
        kueue:
          managementState: Removed
  - name: kserve-vllm-model
    fileprefix: llama-32-3b
    rewrite:
      metadata:
        name: llama-32-3b
      spec:
        destination:
          namespace: model-serving
    values:
      fullnameOverride: llama-32-3b
      displaynameOverride: Llama 3.2 3B Instruct
      model:
        uri: oci://quay.io/jharmison/models:meta-llama--llama-3_2-3b-instruct-modelcar
        extraArgs:
          - --enable-auto-tool-choice
          - --tool-call-parser=llama3_json
          - --chat-template=/app/data/template/tool_chat_template_llama3.2_json.jinja
      scaling:
        minReplicas: 1
        maxReplicas: 3
        retentionPeriod: 1m
        progressDeadline: 60m
        scaleTarget: 5
  - name: summit-demo
    values:
      models:
        - url: https://llama-32-3b-model-serving.apps.{{ .Values.cluster.name }}.{{ .Values.cluster.baseDomain }}/v1
          model: llama-32-3b
          maxTokens: 131072
